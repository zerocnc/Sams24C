# Quiz

1. What's the difference between an integer variable and a floating-point variable?

   An integer varible is whole number while a floating-point number is a decimal number.

2. Give two reason for using a double-precision floating-point variable (type double) instead of a single-precision floating-pooint variable (type float).

   When numbers either get large or small, the precision will be needed to record a lower number that a single precision can capture. Also, code can be ported to a different machine that will allow the definition to be more target to that machine.

3. What are five rules that you know are always true when allocating size for variables?
